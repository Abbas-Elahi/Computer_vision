{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc9cced8-55ee-463c-b172-edf6dd9a79dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "def getFaceBox(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth  = frameOpencvDnn.shape[1]\n",
    "\n",
    "    blob = cv.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    bboxes = []\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            cv.rectangle(frameOpencvDnn, (x1, y1), (x2, y2),\n",
    "                         (0, 255, 0), int(round(frameHeight/150)), 8)\n",
    "\n",
    "    return frameOpencvDnn, bboxes\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Use this script to run age and gender recognition using OpenCV.')\n",
    "parser.add_argument('--input', default=\"\", help='Path to input image or video file. Skip this argument to capture frames from a camera.')\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "faceProto = \"../xmltxt/opencv_face_detector.pbtxt\"\n",
    "faceModel = \"../xmltxt/opencv_face_detector_uint8.pb\"\n",
    "\n",
    "ageProto = \"../xmltxt/age_deploy.prototxt\"\n",
    "ageModel = \"../xmltxt/age_net.caffemodel\"\n",
    "\n",
    "genderProto = \"../xmltxt/gender_deploy.prototxt\"\n",
    "genderModel = \"../xmltxt/gender_net.caffemodel\"\n",
    "\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "genderList = ['Male', 'Female']\n",
    "\n",
    "ageNet = cv.dnn.readNet(ageModel, ageProto)\n",
    "genderNet = cv.dnn.readNet(genderModel, genderProto)\n",
    "faceNet = cv.dnn.readNet(faceModel, faceProto)\n",
    "\n",
    "cap = cv.VideoCapture(args.input if args.input else 1, cv.CAP_DSHOW)\n",
    "padding = 20\n",
    "\n",
    "while True:\n",
    "    t = time.time()\n",
    "    hasFrame, frame = cap.read()\n",
    "    if not hasFrame or frame is None:\n",
    "        break\n",
    "\n",
    "    frameFace, bboxes = getFaceBox(faceNet, frame)\n",
    "\n",
    "    if not bboxes:\n",
    "        cv.imshow(\"Age Gender Demo\", frameFace)\n",
    "        if cv.waitKey(1) & 0xFF in (ord('q'), 27):\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        face = frame[\n",
    "            max(0, bbox[1]-padding):min(bbox[3]+padding, frame.shape[0]-1),\n",
    "            max(0, bbox[0]-padding):min(bbox[2]+padding, frame.shape[1]-1)\n",
    "        ]\n",
    "\n",
    "        if face.size == 0:\n",
    "            continue\n",
    "\n",
    "        blob = cv.dnn.blobFromImage(face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "\n",
    "        genderNet.setInput(blob)\n",
    "        genderPreds = genderNet.forward()\n",
    "        gender = genderList[genderPreds[0].argmax()]\n",
    "        # print(\"Gender : {}, conf = {:.3f}\".format(gender, genderPreds[0].max()))\n",
    "\n",
    "        ageNet.setInput(blob)\n",
    "        agePreds = ageNet.forward()\n",
    "        age = ageList[agePreds[0].argmax()]\n",
    "        # print(\"Age : {}, conf = {:.3f}\".format(age, agePreds[0].max()))\n",
    "\n",
    "        label = \"{},{}\".format(gender, age)\n",
    "        cv.putText(frameFace, label, (bbox[0], max(0, bbox[1]-10)),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2, cv.LINE_AA)\n",
    "\n",
    "    cv.imshow(\"Age Gender Demo\", frameFace)\n",
    "    # print(\"time : {:.3f}\".format(time.time() - t))\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF in (ord('q'), 27):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea4d096-b41f-492d-ada6-88f892a0359e",
   "metadata": {},
   "source": [
    "### Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d1b74-e40e-4d89-ac93-ef460e315307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = cv2.FaceDetectorYN_create('face_detection_yunet_2022mar.onnx', '', (320, 320), 0.9, 0.3, 5000)\n",
    "cam = cv2.VideoCapture(0)\n",
    "model_age = cv2.dnn.readNetFromCaffe(\"age_deploy.prototxt\", \"age_net.caffemodel\")\n",
    "model_gender = cv2.dnn.readNetFromCaffe(\"gender_deploy.prototxt\", \"gender_net.caffemodel\")\n",
    "age_list = [('0-2'), ('4-6'), ('8-12'), ('15-20'), ('25-32'), ('30-43'), ('48-53'), ('60-100')]\n",
    "gender_list = ['Male', 'Female']\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    h, w, _ = frame.shape\n",
    "    model.setInputSize((w, h))\n",
    "    _, results = model.detect(frame)  \n",
    "\n",
    "    if results is not None:\n",
    "        for res in results:  \n",
    "            x1, y1, x2, y2 = map(int, res[:4])  \n",
    "            x1 = max(0, x1)\n",
    "            y1 = max(0, y1)\n",
    "            x2 = min(w, x2)\n",
    "            y2 = min(h, y2)\n",
    "            \n",
    "            crop = frame[y1:y2, x1:x2] \n",
    "            if crop.size == 0:  \n",
    "                continue\n",
    "                \n",
    "            blob = cv2.dnn.blobFromImage(crop, 1.0, (227, 227), \n",
    "                                         (78.4263377603, 87.7689143744, 114.895847746), \n",
    "                                         swapRB=False)\n",
    "            \n",
    "            model_age.setInput(blob)\n",
    "            pred_age = model_age.forward()\n",
    "            age = age_list[pred_age[0].argmax()]\n",
    "            \n",
    "            model_gender.setInput(blob)\n",
    "            pred_gender = model_gender.forward()\n",
    "            gender = gender_list[pred_gender[0].argmax()]\n",
    "            \n",
    "            text = f\"{gender}, {age}\"\n",
    "            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "            cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.8, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Camera', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
